<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Portfolio</title>
        <link rel="icon" type="image/x-icon" href="assets/img/hmd.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v5.15.1/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
    </head>
    <body id="page-top">
        <!-- <button onclick="topFunction()" id="TopBtn" title="Go to top"><b>UP</b></button> -->
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-dark fixed-top" id="mainNav">
            <div class="container">
                <!-- <a class="navbar-brand js-scroll-trigger" href="index.html"><img src="assets/img/navbar-logo.svg" alt="" /></a> -->
                <ul class="navbar-nav text-uppercase ml-auto">
                    <li class="nav-item"><a class="nav-link" href="index.html">Home</a></li>
                </ul>
                <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
                    Menu
                    <i class="fas fa-bars ml-1"></i>
                </button>
                <div class="collapse navbar-collapse" id="navbarResponsive">
                    <ul class="navbar-nav text-uppercase ml-auto">
                        <li class="nav-item"><a class="nav-link" href="about.html">About</a></li>
                        <li class="nav-item"><a class="nav-link" href="speaking.html">Speaking</a></li>
                        <li class="nav-item"><a class="nav-link" href="press.html">Press</a></li>
                        <li class="nav-item"><a class="nav-link" href="publications.html">Portfolio</a></li>
                        <li class="nav-item"><a class="nav-link" href="hobbies.html">My Hobbies</a></li>
                        <li class="nav-item"><a class="nav-link" href="contact.html">Contact</a></li>
                    </ul>
                </div>
            </div>
        </nav>
        <!-- Masthead-->
        <header class="masthead" style="background-image: url(assets/img/headers/header-contact3.jpg)">
            <div class="masthead-overlay"></div>
            <div class="container">
                <div class="masthead-heading text-white">Stuff I have worked on.</div>
            </div>
        </header>
                <!-- Portfolio Grid-->
                <section class="page-section">
                    <div class="container">
                        <div class="text-center">
                            <h2 class="section-heading text-uppercase">VR Projects</h2>
                            <p class="item-intro text-muted">Some of the stuff I have worked on.</p>
                        </div>
                        <div class="row">
                            <div class="row">
                                <div class="col-lg-4 col-sm-6 mb-4">
                                    <div class="prj-container">
                                        <a class="portfolio-link" data-toggle="modal" href="#ytvideo7">
                                            <img src="assets/img/portfolio/publicspeaking.png" alt="" class="project-image">
                                            <div class="project-middle">
                                            <div class="project-text">VRET Fear of Public Speaking </div>
                                            </div>
                                        </a>
                                    </div>
                                </div>
                                <div class="col-lg-4 col-sm-6 mb-4">
                                    <div class="prj-container">
                                        <a class="portfolio-link" data-toggle="modal" href="#ytvideo0">
                                            <img src="assets/img/portfolio/apraxia.png" alt="" class="project-image">
                                            <div class="project-middle">
                                            <div class="project-text">Gesture Performance Schizophrenia </div>
                                            </div>
                                        </a>
                                    </div>
                                </div>
                            <div class="col-lg-4 col-sm-6 mb-4">
                                <div class="prj-container">
                                    <a class="portfolio-link" data-toggle="modal" href="#ytvideo1">
                                        <img src="assets/img/portfolio/social.jpg" alt="" class="project-image">
                                        <div class="project-middle">
                                        <div class="project-text">Bias and Social Context</div>
                                        </div>
                                    </a>
                                </div>
                            </div>
                            <div class="col-lg-4 col-sm-6 mb-4">
                                    <div class="prj-container">
                                        <a class="portfolio-link" data-toggle="modal" href="#ytvideo2">
                                            <img src="assets/img/portfolio/einstein.jpg" alt="" class="project-image">
                                            <div class="project-middle">
                                            <div class="project-text">BEinstein</div>
                                            </div>
                                        </a>
                                    </div>
                            </div>
                            <div class="col-lg-4 col-sm-6 mb-4">
                                <div class="prj-container">
                                    <a class="portfolio-link" data-toggle="modal" href="#ytvideo3">
                                        <img src="assets/img/portfolio/parents.jpg" alt="" class="project-image">
                                        <div class="project-middle">
                                        <div class="project-text">Parental Empathy</div>
                                        </div>
                                    </a>
                                </div>
                            </div>
                            <div class="col-lg-4 col-sm-6 mb-4 mb-lg-0">
                                <div class="prj-container">
                                    <a class="portfolio-link" data-toggle="modal" href="#ytvideo4">
                                        <img src="assets/img/portfolio/speaking.jpg" alt="" class="project-image">
                                        <div class="project-middle">
                                        <div class="project-text">Illusory Agency</div>
                                        </div>
                                    </a>
                                </div>
                            </div>
                            <div class="col-lg-4 col-sm-6 mb-4 mb-sm-0">
                                <div class="prj-container">
                                    <a class="portfolio-link" data-toggle="modal" href="#ytvideo5">
                                        <img src="assets/img/portfolio/bias.jpg" alt="" class="project-image">
                                        <div class="project-middle">
                                        <div class="project-text">Racial Bias</div>
                                        </div>
                                    </a>
                                </div>
                            </div>
                            <div class="col-lg-4 col-sm-6 mb-4">
                                <div class="prj-container">
                                    <a class="portfolio-link" data-toggle="modal" href="#ytvideo6">
                                        <img src="assets/img/portfolio/child.jpg" alt="" class="project-image">
                                        <div class="project-middle">
                                        <div class="project-text">Child Embodiment</div>
                                        </div>
                                    </a>
                                </div>
                            </div>
                            <!-- Use this to center image if no content left/right -->
                            <!-- <div class="col-lg-4 col-sm-6 mb-4">
                                <div class="prj-container">
                                </div>
                            </div> -->
                            <div class="col-lg-4 col-sm-6 mb-4">
                                <div class="prj-container">
                                    <a class="portfolio-link" data-toggle="modal" href="#modalvideo1">
                                        <img src="assets/img/portfolio/childvoice.jpg" alt="" class="project-image">
                                        <div class="project-middle">
                                        <div class="project-text">A Child's Voice</div>
                                        </div>
                                    </a>
                                </div>
                            </div>
                        </div>
                    </div>
                </section>
        <!-- Journal Articles-->
        <section class="page-section bg-light">
            <div class="container">
                <!--2020-->
                <div class="text-center">
                    <h2 class="section-heading text-uppercase">Journal Articles</h2>
                </div>
                <!-- <h2>Journal Articles</h2>
                <hr class="rounded">
                <br><br> -->
                <div class="row">
                    <div class="col-md-3">
                        <h2>2024</h2> 
                    </div>
                    <div class="col-md-9">
                        <h5><a class="four" href="https://www.cell.com/heliyon/fulltext/S2405-8440(24)13612-2" target="_blank">Virtual reality exergames for enhancing engagement in stroke rehabilitation: A narrative review.</a> </h5>
                        <small>C Hadjipanayi, D Banakou, D Michael-Grigoriou (2024)<br>                         
                        Heliyon, 10:18, e37581</small>
                        <br><br>
                        <h5><a class="four" href="https://formative.jmir.org/2024/1/e52212" target="_blank">Desensitizing Anxiety Through Imperceptible Change: Feasibility Study on a Paradigm for Single-Session Exposure Therapy for Fear of Public Speaking.</a> </h5>
                        <small>D Banakou, T Johnston, A Beacco, G Senel, M Slater (2024)<br>                         
                        JMIR Form Res 2024;8:e52212</small>
                        <br><br>
                       <h5><a class="four" href="https://link.springer.com/article/10.1007/s00779-024-01812-w" target="_blank">Cultivating empathy through narratives in virtual reality: a review.</a> </h5>
                       <small>C Hadjipanayi, M Christofi, D Banakou, D Michael-Grigoriou (2024)<br>                         
                        Personal and Ubiquitous Computing 10.1007/s00779-024-01812-w</small>
                       <br><br>
                   </div>
                   <div class="col-md-3">
                        <h2>2023</h2> 
                     </div>
                     <div class="col-md-9">
                        <h5><a class="four" href="https://www.frontiersin.org/articles/10.3389/frvir.2023.1242587/full" target="_blank">Haptic feedback in a virtual crowd scenario improves the emotional response.</a> </h5>
                        <small>RK Venkatesan, D Banakou, M Slater, M Manivannan (2023)<br>                         
                            Frontiers in Virtual Reality Sec. Haptics 4:1242587</small>
                        <br><br>
                        <h5><a class="four" href="https://www.frontiersin.org/articles/10.3389/frvir.2023.1294539/full" target="_blank">A comparison of two methods for moving through a virtual environment: walking in place and interactive redirected walking.</a> </h5>
                        <small>D Banakou, M Slater (2023)<br>                         
                            Frontiers in Virtual Reality Sec. Virtual Reality and Human Behaviour 4:1294539</small>
                        <br><br>
                        <h5><a class="four" href="https://www.frontiersin.org/articles/10.3389/fpsyt.2023.1191601/full" target="_blank">Using virtual reality to assess gesture performance deficits in schizophrenia patients.</a> </h5>
                        <small>A Pavlidou, G Gorisse, D Banakou, S Walther (2023)<br>                         
                            Frontiers in Psychiatry 14:1191601</small>
                        <br><br>
                        <h5><a class="four" href="https://www.frontiersin.org/articles/10.3389/frvir.2023.1065863/full" target="_blank">Art as therapy in virtual reality: A scoping review.</a> </h5>
                        <small>C Hadjipanayi, D Banakou, D Michael-Grigoriou  (2023)<br>                         
                            Frontiers in Virtual Reality 4:1065863</small>
                        <br><br>
                    </div>
                    <div class="col-md-3">
                        <h2>2022</h2> 
                     </div>
                     <div class="col-md-9">
                        <h5><a class="four" href="https://pubmed.ncbi.nlm.nih.gov/36034584/" target="_blank">The Sentiment of a Virtual Rock Concert.</a> </h5>
                        <small>M Slater, C Cabriera, G Senel, D Banakou, A Beacco, R Oliva, J Gallego (2022)<br>                         
                        in Virtual Reality 23:1-25</small>
                        <br><br>
                        <h5><a class="four" href="https://static.frontiersin.org/articles/10.3389/frvir.2022.914392/full" target="_blank">A Separate Reality: An Update on Place Illusion and Plausibility in Virtual Reality.</a> </h5>
                        <small>M Slater, D Banakou, A Beacco, J Gallego, F Macia-Varela, R Oliva (2022)<br>                         
                        Frontiers in Virtual Reality 3:914392</small>
                        <br><br>
                    </div>
                    <div class="col-md-3">
                       <h2>2021</h2> 
                    </div>
                        <div class="col-md-9">
                            <h5><a class="four" href="https://www.nature.com/articles/s41598-021-03373-x" target="_blank">Self-observation of a virtual body-double engaged in social interaction reduces persecutory thoughts.</a> </h5>
                            <small>G Gorisse, G Şenel, D Banakou, A Beacco, R Oliva, D Freeman, M Slater (2021)<br>                         
                            Scientific Repports 11:23923</small>
                            <br><br>
                            <h5><a class="four" href="https://journals.sagepub.com/doi/full/10.1177/09637214211046954" target="_blank">The Golden Rule as a Paradigm for Fostering Prosocial Behavior With Virtual Reality.</a> </h5>
                            <small>M Slater, D Banakou (2021)<br>                         
                            Current Directions in Psychological Science</small>
                            <br><br>
                            <h5><a class="four" href="https://www.frontiersin.org/articles/10.3389/frvir.2021.695673/full" target="_blank">The Influence of Embodiment as a Cartoon Character on Public Speaking Anxiety.</a> </h5>
                            <small>A I Bellido Rivas, X Navarro, D Banakou, R Oliva, V Orvalho, M Slater (2021)<br>
                            Frontiers in Virtual Reality 11:2281</small>
                            <br><br>
                            <h5><a class="four" href="https://royalsocietypublishing.org/doi/10.1098/rsos.210537" target="_blank">Evaluating participant responses to a virtual reality experience using reinforcement learning.</a> </h5>
                            <small> J Llobera, A Beacco, R Oliva, G Şenel, D Banakou, Mel Slater (2021)
                            <br>Royal Society Open Science 8:9</small>
                            </small>
                            <br><br>
                            <h5><a class="four" href="https://www.frontiersin.org/articles/10.3389/fpsyg.2021.691909/full" target="_blank">Editorial: Neuropsychological and Cognitive-Behavioral Assessment of Neurodegenerative Disease and Rehabilitation Using New Technologies and Virtual Reality.</a> </h5>
                            <small> M Matamala-Gomez, F Stasolla, S Seinfeld, A O. Caffò, D Banakou, S Bottiroli (2021)
                            <br>Frontiers in Psychology 12:691909</small>
                            </small>
                            <br><br>
                        </div>
                </div>
                <br>
                <div class="row">
                    <div class="col-md-3">
                       <h2>2020</h2> 
                    </div>
                        <div class="col-md-9">
                            <h5><a class="four" href="https://royalsocietypublishing.org/doi/10.1098/rsos.201848" target="_blank"> Virtual body ownership and its consequences for implicit racial bias are dependent on social context.</a> </h5>
                            <small> D Banakou, A Beacco, S Neyret, M Blasco-Oliver, S Seinfeld, Mel Slater (2020)
                            <br>Royal Society Open Science 7:201848</small>
                            </small>
                            <br><br>
                            <h5><a class="four" href="https://www.frontiersin.org/articles/10.3389/frvir.2020.561558/full" target="_blank">The Rocketbox library and the utility of freely available rigged avatars for procedural animation of virtual humans and embodiment.</a> </h5>
                            <small> M Gonzalez-Franco, E Ofek, Y Pan, A Antley, A Steed, B Spanlang, A Maselli, D Banakou, N Pelechano, S Orts-Escolano, V Orvalho, L Trutoiu, M Wojcik, M V Sanchez-Vives, J Bailenson, M Slater, J Lanier (2020)
                            <br>Frontiers in Virtual Reality 1:561558</small>
                            </small>
                            <br><br>
                            <h5><a class="four" href="https://www.frontiersin.org/articles/10.3389/fpsyg.2020.510787/full" target="_blank">Exploring the effect of cooperation in reducing implicit racial bias and its relationship with dispositional empathy and political attitudes.</a> </h5>
                            <small>I Patané<sup> &#8224; </sup>, A Lelgouarch<sup> &#8224; </sup>, D Banakou<sup> &#8224; </sup>, G Verdelet, C Desoche, E Koun, R Salemme, M Slater, A Farnè (2020)<br>
                            Frontiers in Psychology, 11:2281</small>
                            <br><br>
                            <h5><a class="four" href="https://www.frontiersin.org/articles/10.3389/fpsyg.2020.02254/full" target="_blank">Social Conformity in Immersive Virtual Environments: The Impact of Agents’ Gaze Behavior.</a> </h5>
                            <small> C Kyrlitsias, D Michael-Grigoriou, D Banakou, M Christofi (2020)
                            <br>Frontiers in Psychology 11:2254</small>
                            </small>
                            <br><br>
                            <h5><a class="four" href="https://www.frontiersin.org/articles/10.3389/fcomp.2020.00023/full" target="_blank">A Virtual Τour of a Hardly Accessible Archaeological Site: the Effect of Immersive Virtual Reality in User Experience, Learning and Attitude Change.</a> </h5>
                            <small> C Kyrlitsias, M Christofi, D Michael-Grigoriou, D Banakou, A Ioannou (2020)
                            <br>Frontiers in Computer Science 2:23</small>
                            </small>
                            <br><br>
                        </div>
                </div>
                <br>
                <div class="row">
                    <div class="col-md-3">
                       <h2>2019</h2> 
                    </div>
                        <div class="col-md-9">
                            <h5><a class="four" href="https://www.sciencedirect.com/science/article/pii/S0010027718303056" target="_blank">A Mechanistic Account of Bodily Resonance and Implicit Bias.</a> </h5>
                            <small> R Bedder, D Bush, D Banakou, T Peck, M Slater, N Burgess (2019)
                            <br>Cognition 184 (1-10)</small>
                            </small>
                        </div>
                </div>
                <br><br>
                <div class="row">
                    <div class="col-md-3">
                       <h2>2018</h2> 
                    </div>
                        <div class="col-md-9">
                            <h5><a class="four" href="https://www.frontiersin.org/articles/10.3389/fpsyg.2018.00917/full" target="_blank">Virtually Being Einstein Results in an Improvement in Cognitive Task Performance and a Decrease in Age Bias.</a> </h5>
                            <small> D Banakou, S Kishore, M Slater (2018)
                            <br>Frontiers in Psychology 9:917</small>
                            </small>
                            <br><br>
                            <h5><a class="four" href="https://www.nature.com/articles/s41598-018-21036-2" target="_blank">Reducing risk and improving maternal perspective-taking and empathy using virtual embodiment.</a> </h5>
                            <small> C Hamilton-Giachritsis, D Banakou, M Quiroga-Garcia, C Giachritsis, M Slater (2018)
                            <br>Scientific Reports 8:14227</small>
                            </small>
                        </div>
                </div>
                <br><br>
                <div class="row">
                    <div class="col-md-3">
                       <h2>2017</h2> 
                    </div>
                        <div class="col-md-9">
                            <h5><a class="four" href="https://www.nature.com/articles/s41598-017-14620-5" target="_blank">Embodiment in a virtual body that speaks produces agency over the speaking but does not necessarily influence subsequent real speaking.</a> </h5>
                            <small> D Banakou, M Slater (2017) 
                            <br>Scientific Reports 7:14227</small>
                            </small>
                            <br><br>
                            <h5><a class="four" href="https://www.nature.com/articles/s41598-017-09497-3" target="_blank">Embodiment in a Child-Like Talking Virtual Body Influences Object Size Perception, Self-Identification, and Subsequent Real Speaking.</a> </h5>
                            <small> A Tajadura-Jiménez<sup> &#8224; </sup>, D Banakou<sup> &#8224; </sup>, N Bianchi-Berthouze, M Slater (2017) 
                            <br>Scientific Reports 7:9637</small>
                            </small>
                        </div>
                </div>
                <br><br>
                <div class="row">
                    <div class="col-md-3">
                       <h2>2016</h2> 
                    </div>
                        <div class="col-md-9">
                            <h5><a class="four" href="https://www.frontiersin.org/articles/10.3389/fnhum.2016.00601/full" target="_blank">Virtual Embodiment of White People in a Black Virtual Body Leads to a Sustained Reduction in their Implicit Racial Bias.</a> </h5>
                            <small> D Banakou, PD Hanumanthu, M Slater (2016)
                            <br>Frontiers in Human Neuroscience 10:601 </small>
                            </small>
                        </div>
                </div>
                <br><br>
                <div class="row">
                    <div class="col-md-3">
                       <h2>2014</h2> 
                    </div>
                        <div class="col-md-9">
                            <h5><a class="four" href="https://www.pnas.org/content/111/49/17678.abstract" target="_blank">Body ownership causes illusory self-attribution of speaking and influences subsequent real speaking.</a> </h5>
                            <small> D Banakou, M Slater (2014)
                            <br>Proceedings of the National Academy of Sciences  U S A (PNAS) 111(49):17678-83 </small>
                            </small>
                        </div>
                </div>
                <br><br>
                <div class="row">
                    <div class="col-md-3">
                       <h2>2013</h2> 
                    </div>
                        <div class="col-md-9">
                            <h5><a class="four" href="https://www.pnas.org/content/110/31/12846.abstract" target="_blank">Illusory ownership of a virtual child body causes overestimation of object sizes and implicit attitude changes.</a> </h5>
                            <small> D Banakou, R Groten, M Slater (2013)
                            <br>Proceedings of the National Academy of Sciences  U S A (PNAS)  1(6):12846–12851</small>
                            </small>
                        </div>
                </div>
                <br><br>
                <div class="row">
                    <div class="col-md-3">
                       <h2>2011</h2> 
                    </div>
                        <div class="col-md-9">
                            <h5><a class="four" href="https://link.springer.com/chapter/10.1007/978-3-642-24571-8_6" target="_blank">Computer Based Video and Virtual Environments in the Study of the Role of Emotions in Moral Behavior. </a> </h5>
                            <small> X Pan, D Banakou, M Slater (2011) 
                            <br> Affective Computing and Intelligent Interaction 6975:52-61 </small>
                            </small>
                        </div>
                </div>
                <br><br>
                <div class="row">
                    <div class="col-md-3">
                        <h2>2010</h2> 
                    </div>
                        <div class="col-md-9">
                            <h5><a class="four" href="https://journals.tdl.org/jvwr/index.php/jvwr/article/view/779" target="_blank">The effects of Avatars’ Gender and Appearance on Social Behaviour in Virtual Worlds. </a> </h5>
                            <small> D Banakou, K Chorianopoulos (2010)
                            <br> Journal of Virtual Worlds Research 2(5):3-16 </small>
                            </small>
                        </div>
                    </div>
                </div>
            </div>
            </section>
            <!-- Footer-->
        <footer class="footer py-4">
            <div class="container">
                <div class="row align-items-center">
                    <div class="col-lg-4 text-lg-left">Copyright © Domna Banakou 2023</div>
                    <div class="col-lg-4 my-3 my-lg-0">
                        <a class="btn btn-dark btn-social mx-2" href="https://twitter.com/domnaban?lang=en" target="_blank"><i class="fab fa-twitter"></i></a>
                        <a class="btn btn-dark btn-social mx-2" href="https://es.linkedin.com/in/domna-banakou-382a672a/" target="_blank"><i class="fab fa-linkedin-in"></i></a>
                        <a class="btn btn-dark btn-social mx-2" href="https://www.pinterest.es/domnaban/_saved/" target="_blank"><i class="fab fa-pinterest"></i></a>
                    </div>
                    <div class="col-lg-4 text-lg-right">
                        <a href="https://goo.gl/maps/LHAuzvdw7jjr7pYy7" target="_blank">NYU Abu Dhabi, <br> Saadiyat Campus, Abu Dhabi, UAE</a>
                    </div>
                </div>
            </div>
        </footer>
        <!-- Portfolio Modals-->
<!-- Modal 0-->
<div class="portfolio-modal modal fade" id="ytvideo7" tabindex="-1" role="dialog" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal"><img src="assets/img/close-icon.svg" alt="Close modal" /></div>
            <div class="container">
                <div class="row justify-content-center">
                    <div class="col-lg-8">
                        <div class="modal-body">
                            <!-- Project Details Go Here-->
                            <h2 class="text-uppercase">Desensitizing Anxiety Through Imperceptible Change: Feasibility Study on a Paradigm for Single-Session Exposure Therapy for Fear of Public Speaking </h2>
                            <p class="item-intro text-muted">A feasibility study to assess single-session VRET for Fear of Public Speaking.</p>
                            <iframe width="720px" height="550px" src="https://www.youtube.com/embed/QFvJMPmdsDE" allowfullscreen></iframe>
                            <br>
                            <p><b>Abstract</b><br>Exposure therapy (ET) for anxiety disorders involves introducing the participant to an anxiety-provoking situation over 
                                several treatment sessions. Each time, the participant is exposed to a higher anxiety-provoking stimulus; for example, in the case of fear 
                                of heights, the participant would successively experience being at a greater height. ET is effective, and its counterpart, virtual reality (VR) 
                                exposure therapy (VRET), where VR substitutes real-world exposure, is equally so. However, ET is time-consuming, requiring several sessions.
                                This study aimed to compare the results of single-session exposure with those of traditional VRET with regard to reducing public speaking anxiety.
                                We introduced a paradigm concerned with public speaking anxiety where the VR exposure occurred in a single session while the participant 
                                interacted with a virtual therapist. Over time, the therapist transformed into an entire audience with almost imperceptible changes. 
                                We carried out a feasibility study with 45 participants, comparing 3 conditions: single-session exposure (n=16, 36%); conventional 
                                multiple-session exposure (n=14, 31%), where the same content was delivered in successive segments over 5 sessions; and a control group 
                                (n=15, 33%), who interacted with a single virtual character to talk about everyday matters. A week later, the participants were required to 
                                speak on a stage in front of a large audience in VR.
                                Across most of the series of conventional public speaking anxiety measures, the single-session exposure was at least as effective in 
                                reducing anxiety as the multiple-session exposure, and both these conditions were better than the control condition. The 12-item Personal 
                                Report of Confidence as a Speaker was used to measure public speaking anxiety levels, where higher values indicated more anxiety. 
                                Using a Bayesian model, the posterior probabilities of improvement compared to a high baseline were at least 1.7 times greater for single- 
                                and multiple-session exposures compared to the control group. The State Perceived Index of Competence was used as a measure of anticipatory 
                                anxiety for speaking on a stage in front of a large audience, where lower values indicated higher anxiety. The probabilities of improvement 
                                were just over 4 times greater for single- and multiple-session exposures compared to the control group for a low baseline and 489 (single) 
                                and 53 (multiple) times greater for a middle baseline.
                                Overall, the results of this feasibility study show that for moderate public speaking anxiety, the paradigm of gradual change in a single session is worth following up with further studies with more severe levels of anxiety and a larger sample size, first with a randomized controlled trial with nonpatients and subsequently, if the outcomes follow those that we have found, with a full clinical trial with patients.                            <ul class="list-inline">
                                <small><i><li>Domna Banakou, Tania Johnston, Alejandro Beacco, Gizem Senel &amp; Mel Slater</li>
                                <li>JMIR Form Res 2024;8:e52212, 22 July 2024</li>
                                <li>doi:<a class="one" href="https://formative.jmir.org/2024/1/e52212" target="_blank">10.2196/52212</a></li></i></small>
                            </ul>

                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>
                <!-- Modal 0-->
                <div class="portfolio-modal modal fade" id="ytvideo0" tabindex="-1" role="dialog" aria-hidden="true">
                    <div class="modal-dialog">
                        <div class="modal-content">
                            <div class="close-modal" data-dismiss="modal"><img src="assets/img/close-icon.svg" alt="Close modal" /></div>
                            <div class="container">
                                <div class="row justify-content-center">
                                    <div class="col-lg-8">
                                        <div class="modal-body">
                                            <!-- Project Details Go Here-->
                                            <h2 class="text-uppercase">Gesture Performance Deficits in Schizophrenia </h2>
                                            <p class="item-intro text-muted">A VR Study Protocol to Assess Gesture Performance Accuracy in Schizophrenia Patients.</p>
                                            <video class="video-portfolio" controls src="assets/img/portfolio/apraxia.MP4" type="video/MP4"></video>
                                            <br>
                                            <p><b>Abstract</b><br>Gesture performance deficits are prevalent in schizophrenia patients and are strongly 
                                                associated with poor social communication skills and community functioning, affecting their overall quality of life. 
                                                Currently, video-recording technology is widely used in clinical settings to assess gesture production deficits in 
                                                schizophrenia patients. Nevertheless, the subjective evaluation of video-recordings can encumber task assessment. 
                                                The present study will aim to use virtual reality to examine its potential use as an alternative tool to objectively 
                                                measure gesture performance accuracy in schizophrenia patients and healthy controls.
                                                Gesture performance in the virtual reality setting will be based on the well-established Test of Upper Limb Apraxia. 
                                                Participants will be immersed in a virtual environment where they will experience themselves being embodied in 
                                                a collocated virtual body seen from a first-person perspective. Motion trackers will be placed on participants' hands 
                                                and elbows to track upper body movements in real-time, and to record gesture movement for later analysis. 
                                                Participants will see a virtual agent sitting across from them, with a virtual table in between. 
                                                The agent will perform various types of gestures and the participants' task will be to imitate those 
                                                gestures as accurately as possible. Measurements from the tracking devices will be stored and analyzed to 
                                                address gesture performance accuracy across groups. This study aims to provide objective measurements of gesture performance accuracy in schizophrenia patients. If successful, the results will provide new knowledge to the gesture literature and offer the potential for novel therapeutic interventions using virtual reality technologies. Such interventions can improve gesturing and thus advance social communication skills in schizophrenia patients.</p>
                                            <ul class="list-inline">
                                                <small><i><li>Anastasia Pavlidou, Geoffrey Gorisse, <br>Domna Banakou &amp; Sebastian Walther</li>
                                                <li>Front. Psychiatry, 9 June 2023</li>
                                                <li>doi:<a class="one" href="https://www.frontiersin.org/articles/10.3389/fpsyt.2023.1191601/full" target="_blank">10.3389/fpsyt.2023.1191601</a></li></i></small>
                                            </ul>
        
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
        <!-- Modal 1-->
        <div class="portfolio-modal modal fade" id="ytvideo1" tabindex="-1" role="dialog" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="close-modal" data-dismiss="modal"><img src="assets/img/close-icon.svg" alt="Close modal" /></div>
                    <div class="container">
                        <div class="row justify-content-center">
                            <div class="col-lg-8">
                                <div class="modal-body">
                                    <!-- Project Details Go Here-->
                                    <h2 class="text-uppercase">Implicit Bias and Social Context</h2>
                                    <p class="item-intro text-muted">Virtual body ownership and changes in implicit racial bias dependent
                                        on the social context.</p>
                                    <iframe width="720px" height="550px" src="https://www.youtube.com/embed/AToran81-Rc" allowfullscreen></iframe>
                                    <br>
                                    <p><b>Abstract</b><br>When people hold implicit biases against a group they typically
                                        engage in discriminatory behaviour against group members. In
                                        the context of the implicit racial bias of ‘white’ against 'black'
                                        people, it has been shown several times that implicit bias is
                                        reduced after a short exposure of embodiment in a dark-skinned
                                        body in virtual reality. Embodiment usually leads to the illusion
                                        of ownership over the virtual body, irrespective of its skin
                                        colour. Previous studies have been carried out in virtual
                                        scenarios that are affectively neutral or positive. Here, we show
                                        that when the scenario is affectively negative the illusion of
                                        body ownership of white participants over a white body is
                                        lessened, and implicit bias is higher for white participants in a
                                        black virtual body. The study was carried out with 92 white
                                        female participants, in a between-groups design with two
                                        factors: BodyType (their virtual body was White or Black) and a
                                        surrounding Crowd was Negative, Neutral or Positive towards
                                        the participant. We argue that negative affect prevents the
                                        formation of new positive associations with black and distress
                                        leads to disownership of the virtual body. Although virtual
                                        reality is often thought of as an ‘empathy machine’ our results
                                        suggest caution, that this may not be universally the case.</p>
                                    <ul class="list-inline">
                                        <small><i><li>Domna Banakou, Alejandro Beacco, <br>Solène Neyret, Marta Blasco-Oliver, Sofia Seinfeld &amp; Mel Slater</li>
                                        <li>R. Soc. Open Sci., 9 Dec 2020</li>
                                        <li>doi:<a class="one" href="https://royalsocietypublishing.org/doi/10.1098/rsos.201848" target="_blank">10.1098/rsos.201848</a></li></i></small>
                                    </ul>

                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <!-- Modal 2-->
        <div class="portfolio-modal modal fade" id="ytvideo2" tabindex="-1" role="dialog" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="close-modal" data-dismiss="modal"><img src="assets/img/close-icon.svg" alt="Close modal" /></div>
                    <div class="container">
                        <div class="row justify-content-center">
                            <div class="col-lg-8">
                                <div class="modal-body">
                                    <!-- Project Details Go Here-->
                                    <h2 class="text-uppercase">BEinstein</h2>
                                    <p class="item-intro text-muted">Being Einstein in Immersive Virtual Reality.</p>
                                    <iframe width="720px" height="550px" src="https://www.youtube.com/embed/TAEM5OlFbnw" allowfullscreen></iframe><br>
                                    <p><b>Abstract</b><br>The brain's body representation is amenable to rapid change, even though we tend to think of our bodies 
                                        as relatively fixed and stable. For example, it has been shown that a life-sized body perceived in 
                                        virtual reality as substituting the participant's real body, can be felt as if it were their own, 
                                        and that the body type can induce perceptual, attitudinal and behavioral changes. Here we show that 
                                        changes can also occur in cognitive processing and specifically, executive functioning. 
                                        Young male participants were embodied in either a virtual body that signifies super-intelligence (Einstein) 
                                        or a (Normal) virtual body of similar age to their own. The Einstein body participants 
                                        performed better on a cognitive task than the Normal body, considering prior cognitive ability (IQ), 
                                        with the improvement greatest for those with low self-esteem. Einstein embodiment also reduced 
                                        implicit bias against older people. Hence virtual body ownership may additionally be used to 
                                        enhance executive functioning.</p>
                                    <ul class="list-inline">
                                        <small><i><li>Domna Banakou, Sameer Kishore &amp; Mel Slater</li>
                                        <li>Front. Psychol., 11 June 2018</li>
                                        <li>doi:<a class="one" href="https://doi.org/10.3389/fpsyg.2018.00917" target="_blank">10.3389/fpsyg.2018.00917</a></li></i></small>
                                    </ul>

                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <!-- Modal 3-->
        <div class="portfolio-modal modal fade" id="ytvideo3" tabindex="-1" role="dialog" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="close-modal" data-dismiss="modal"><img src="assets/img/close-icon.svg" alt="Close modal" /></div>
                    <div class="container">
                        <div class="row justify-content-center">
                            <div class="col-lg-8">
                                <div class="modal-body">
                                    <!-- Project Details Go Here-->
                                    <h2 class="text-uppercase">Parental Empathy</h2>
                                    <p class="item-intro text-muted">Improving maternal perspective-taking and empathy using virtual embodiment.</p>
                                    <iframe width="720px" height="550px" src="https://www.youtube.com/embed/u6rAZGsT9hE" allowfullscreen></iframe>
                                    <p><b>Abstract</b><br>The ability to perspective-take (cognitive awareness of another’s state) and empathise (emotional/affective response) 
                                        are important characteristics for sensitive, co-operative and constructive parenting, which assists in developing 
                                        adaptive functioning for children. For the first time, immersive virtual reality was used to place parents in the 
                                        position of a child in order to assess impact on perspective-taking and empathy. This novel study was conducted with 
                                        non-high risk Spanish mothers. Mothers were virtually embodied as a 4-year-old child, experienced from the first-person perspective and
                                         with virtual and real body movements synchronised. They interacted with a ‘mother avatar’, which responded 
                                         either in a Positive or Negative way. Participants reported a strong body ownership illusion for the child 
                                         body that led to cognitive, emotional and physical reactions. Experiencing negative maternal behavior increased 
                                         levels of empathy. In addition, the Negative mother led to increased feelings of fear of violence. Physiological 
                                         data indicated greater stress in the Negative than Positive condition. Although further research is required to 
                                         assess the effectiveness of such methods, any improvement in empathy that leads to a change in parenting behavior 
                                         has the potential to impact on developmental outcomes for children.</p>
                                    <ul class="list-inline">
                                        <small><i><li>Catherine Hamilton-Giachritsis, Domna Banakou, <br> Manuela Garcia Quiroga, Christos Giachritsis &amp; Mel Slater</li>
                                        <li>Sci Rep., 14 Feb 2018</li>
                                        <li>doi:<a class="one" href="https://www.nature.com/articles/s41598-018-21036-2" target="_blank">10.1038/s41598-018-21036-2</a></li></i></small>
                                    </ul>

                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <!-- Modal 4-->
        <div class="portfolio-modal modal fade" id="ytvideo4" tabindex="-1" role="dialog" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="close-modal" data-dismiss="modal"><img src="assets/img/close-icon.svg" alt="Close modal" /></div>
                    <div class="container">
                        <div class="row justify-content-center">
                            <div class="col-lg-8">
                                <div class="modal-body">
                                    <!-- Project Details Go Here-->
                                    <h2 class="text-uppercase">Illusory Agency</h2>
                                    <p class="item-intro text-muted">Speaking with your avatar's voice.</p>
                                    <iframe width="720px" height="550px" src="https://www.youtube.com/embed/_gw-7SbUxUQ" allowfullscreen></iframe>
                                    <p><b>Abstract</b><br>When we carry out an act, we typically attribute the action to ourselves, the sense of agency. 
                                        Explanations for agency include conscious prior intention to act, followed by observation of the sensory 
                                        consequences; brain activity that involves the feed-forward prediction of the consequences combined with 
                                        rapid inverse motor prediction to fine-tune the action in real time; priming where there is, e.g., a prior 
                                        command to perform the act; a cause (the intention to act) preceding the effect (the results of the action); 
                                        and common-sense rules of attribution of physical causality satisfied. We describe an experiment where 
                                        participants falsely attributed an act to themselves under conditions that apparently cannot be explained 
                                        by these theories. A life-sized virtual body seen from the first-person perspective in 3D stereo, 
                                        as if substituting the real body, was used to induce the illusion of ownership over the virtual body. Half of the 
                                        44 experimental participants experienced virtual body movements that were synchronous with their own movements (sync), 
                                        and the other half asynchronous (async). The virtual body, seen in a mirror, spoke with corresponding lip movements, 
                                        and for half of the participants this was accompanied by synchronous vibrotactile stimulation on the thyroid 
                                        cartilage but this was not so for the other half. Participants experiencing sync misattributed the 
                                        speaking to themselves and also shifted the fundamental frequency of their later utterances toward the stimulus 
                                        ice. Synchronous vibrotactile stimulation also contributed to these results. We show that these findings can be explained by current theories of 
                                        agency, provided that the critical role of ownership over the virtual body is taken into account.</p>
                                    <ul class="list-inline">
                                        <small><i><li>Domna Banakou &amp; Mel Slater</li>
                                        <li>PNAS, 9 Dec 2014</li>
                                        <li>doi:<a class="one" href="https://www.pnas.org/content/111/49/17678.abstract" target="_blank">10.1073/pnas.1414936111</a></li></i></small>
                                    </ul>

                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <!-- Modal 5-->
        <div class="portfolio-modal modal fade" id="ytvideo5" tabindex="-1" role="dialog" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="close-modal" data-dismiss="modal"><img src="assets/img/close-icon.svg" alt="Close modal" /></div>
                    <div class="container">
                        <div class="row justify-content-center">
                            <div class="col-lg-8">
                                <div class="modal-body">
                                    <!-- Project Details Go Here-->
                                    <h2 class="text-uppercase">Implicit Racial Bias</h2>
                                    <p class="item-intro text-muted">Embodying a Black virtual body leads to a sustained reduction in racial bias.</p>
                                    <iframe width="720px" height="550px" src="https://www.youtube.com/embed/RcBJ1sCPv_I" allowfullscreen></iframe>
                                    <p><b>Abstract</b><br>Virtual reality can be used to visually substitute a person's body by a life-sized virtual one. 
                                        Such embodiment results in a perceptual illusion of body ownership over the virtual body. 
                                        Previous research has shown that the form of the virtual body can influence implicit attitudes. In particular, 
                                        embodying White people in a Black virtual body is associated with an immediate decrease in their implicit racial bias 
                                        against Black people. We tested whether the reduction in implicit bias lasts for at least 1 week and whether it is 
                                        enhanced by multiple exposures. Ninety (90) female participants where the virtual body was either Black or White. 
                                        Participants were required to follow a virtual Tai Chi teacher who was either Asian or European Caucasian. Each participant 
                                        had 1, 2, or 3 exposures separated by days. Implicit racial bias was measured 1 week before their first exposure and 1 week after 
                                        their last. The results show that implicit bias decreased more for those with the Black virtual body than the White. 
                                        There was also some evidence of a general decrease in bias independently of body type for which possible explanations are put forward.</p>
                                    <ul class="list-inline">
                                        <small><i><li>Domna Banakou, Parasuram D. Hanumanthu &amp; Mel Slater</li>
                                        <li>Front. Hum. Neurosci., 29 Nov 2016</li>
                                        <li>doi:<a class="one" href="https://www.frontiersin.org/articles/10.3389/fnhum.2016.00601/full" target="_blank">10.3389/fnhum.2016.00601</a></li></i></small>
                                    </ul>

                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <!-- Modal 6-->
        <div class="portfolio-modal modal fade" id="ytvideo6" tabindex="-1" role="dialog" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="close-modal" data-dismiss="modal"><img src="assets/img/close-icon.svg" alt="Close modal" /></div>
                    <div class="container">
                        <div class="row justify-content-center">
                            <div class="col-lg-8">
                                <div class="modal-body">
                                    <!-- Project Details Go Here-->
                                    <h2 class="text-uppercase">Child Embodiment</h2>
                                    <p class="item-intro text-muted">Experiencing being a child in Virtual Reality.</p>
                                    <iframe width="720px" height="550px" src="https://www.youtube.com/embed/8Oy83OVgbSM" allowfullscreen></iframe>
                                    <p><b>Abstract</b><br>An illusory sensation of ownership over a surrogate limb or whole body can be induced through 
                                        specific forms of multisensory stimulation, such as synchronous visuotactile tapping on the hidden real and 
                                        visible rubber hand in the rubber hand illusion. Such methods have been used to induce ownership over a manikin 
                                         a virtual body that substitute the real body, as seen from first-person perspective, through a head-mounted 
                                         display. However, the perceptual and behavioral consequences of such transformed body ownership have hardly 
                                         been explored. Immersive virtual reality was used to embody 30 adults as a 4-y-old child,
                                          and as an adult body scaled to the same height as the child, experienced from the first-person 
                                          perspective, and with virtual and real body movements synchronized. The result was a strong body-ownership 
                                          illusion equally for child and scaled-down adult. Moreover there was an overestimation of the sizes of objects compared with a 
                                          nonembodied baseline, which was significantly greater for the child condition compared with the scaled-down adult condition. 
                                          An implicit association test showed that being in a child's body resulted in significantly faster reaction times for the classification of self with child-like 
                                          compared with adult-like attributes. A second experiment with an additional 16 participants extinguished the ownership 
                                          illusion by using visuomotor asynchrony, with all else equal. The size-estimation and implicit association 
                                          test differences between child and scaled-down adult were also extinguished, demonstrating perceptual and 
                                          behavioral correlates of body-ownership illusions that occur as a function of the type of body in which 
                                          embodiment occurs.</p>
                                    <ul class="list-inline">
                                        <small><i><li>Domna Banakou, Raphaela Groten &amp; Mel Slater</li>
                                        <li>PNAS, 30 July 2013</li>
                                        <li>doi:<a class="one" href="https://www.pnas.org/content/110/31/12846.abstract" target="_blank">10.1073/pnas.1306779110</a></li></i></small>
                                    </ul>

                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>      
        <!-- Modal 7-->
                <div class="portfolio-modal modal fade" id="modalvideo1" tabindex="-1" role="dialog" aria-hidden="true">
                    <div class="modal-dialog">
                        <div class="modal-content">
                            <div class="close-modal" data-dismiss="modal"><img src="assets/img/close-icon.svg" alt="Close modal" /></div>
                            <div class="container">
                                <div class="row justify-content-center">
                                    <div class="col-lg-8">
                                        <div class="modal-body">
                                            <!-- Project Details Go Here-->
                                            <h2 class="text-uppercase">A child's Voice</h2>
                                            <p class="item-intro text-muted">The embodiment illusion depends on the voice 
                                                feedback being congruent with the age of the virtual body.</p>
                                            <video class="video-portfolio" controls src="assets/img/portfolio/childvoice.mov" type="video/mov"></video>
                                            <p><b>Abstract</b><br>People's mental representations of their own body are malleable and continuously updated through sensory cues. 
                                                Altering one's body-representation can lead to changes in object perception and implicit attitudes. Virtual reality has been 
                                                used to embody adults in the body of a 4-year-old child or a scaled-down adult body. Child embodiment was found to cause an 
                                                overestimation of object sizes, approximately double that during adult embodiment, and identification of the self with child-like 
                                                attributes. Here we tested the contribution of auditory cues related to one's own voice to these visually-driven effects. 
                                                In a 2<span>&#215;</span>2 factorial design, visual and auditory feedback on one's own body were varied across conditions, which included 
                                                embodiment in a child or scaled-down adult body, and real (undistorted) or child-like voice feedback. The results replicated, 
                                                in an older population, previous findings regarding size estimations and implicit attitudes. Further, although auditory cues 
                                                were not found to enhance these effects, we show that the strength of the embodiment illusion depends on the child-like voice 
                                                feedback being congruent or incongruent with the age of the virtual body. Results also showed the positive emotional impact of 
                                                the illusion of owning a child's body, opening up possibilities for health applications.</p>
                                            <ul class="list-inline">
                                                <small><i><li>Ana Tajadura-Jiménez, Domna Banakou, <br>Nadia Bianchi-Berthouze &amp; Mel Slater</li>
                                                <li>Sci Rep., 14 March 2018</li>
                                                <li>doi:<a class="one" href="https://www.nature.com/articles/s41598-017-09497-3" target="_blank">10.1038/s41598-017-09497-3</a></li></i></small>
                                            </ul>
        
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>  
            <!-- Modal 8-->
 
        <!-- Bootstrap core JS-->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Third party plugin JS-->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.4.1/jquery.easing.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
        <!-- <script src="js/video.js"></script> -->
    </body>
</html>
